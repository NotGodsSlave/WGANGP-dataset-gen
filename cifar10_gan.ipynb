{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041131ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from wasserstein_loss import wasserstein_generator_loss, wasserstein_discriminator_loss\n",
    "from image_wgan_gp import imageWGANGP\n",
    "from GANmonitor import GANMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cb552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0b9e9",
   "metadata": {},
   "source": [
    "# Building the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa790e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, filters, size, strides, upsize, apply_dropout=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    x = layers.UpSampling2D(upsize)(x)\n",
    "    x = layers.Conv2D(\n",
    "        filters, size, strides=strides, padding=\"same\", use_bias=False\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if apply_dropout:\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides, apply_batchnorm=False, apply_layernorm=True, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    x = layers.Conv2D(filters, size, strides=strides, padding='same',\n",
    "                                    kernel_initializer=initializer, use_bias=False)(x)\n",
    "    if apply_batchnorm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    if apply_layernorm:\n",
    "        x = layers.LayerNormalization()(x)\n",
    "    if apply_dropout:\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a44129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim=128, num_classes=10, img_height=32, img_width=32, img_channels=3):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    in_channels = latent_dim+num_classes\n",
    "    inputs = layers.Input((in_channels,))\n",
    "    \n",
    "    x = inputs\n",
    "    x = layers.Dense(4*4*in_channels)(x)\n",
    "    x = layers.Reshape((4,4,in_channels))(x)\n",
    "    \n",
    "    x = upsample_block(x, filters = 256, size = 3, strides = 1, upsize = (2,2))\n",
    "    x = upsample_block(x, filters = 128, size = 3, strides = 1, upsize = (2,2))\n",
    "    x = upsample_block(x, filters = 64, size = 3, strides = 1, upsize = (2,2))\n",
    "    \n",
    "    last = tf.keras.layers.Conv2D(img_channels, 7,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=initializer,\n",
    "                                 activation='tanh')\n",
    "        \n",
    "    x = last(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs = x, name=\"generator\")\n",
    "\n",
    "def build_discriminator(num_classes=10, img_height=32, img_width=32, img_channels=3):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    inp = layers.Input((img_height,img_width,img_channels))\n",
    "    label = layers.Input((img_height,img_width,num_classes))\n",
    "    \n",
    "    x = layers.concatenate([inp, label])\n",
    "    \n",
    "    x = convolution_block(x, filters=64, size = 5, strides = 2)\n",
    "    x = convolution_block(x, filters=128, size = 5, strides = 2)\n",
    "    x = convolution_block(x, filters=256, size = 5, strides = 2)\n",
    "    x = convolution_block(x, filters=512, size = 5, strides = 2)\n",
    "    \n",
    "    flatten = layers.Flatten()\n",
    "    last = layers.Dense(1)\n",
    "    \n",
    "    x = flatten(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = last(x)\n",
    "    \n",
    "    return Model(inputs=[inp,label], outputs=x, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e379d1",
   "metadata": {},
   "source": [
    "# Reading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077aba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96c9598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (50000, 32, 32, 3)\n",
      "Shape of training labels: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = (x_train.astype(\"float32\") - 127.5) / 127.5\n",
    "x_train = np.reshape(x_train, (-1, img_height, img_width, img_channels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {x_train.shape}\")\n",
    "print(f\"Shape of training labels: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb45959",
   "metadata": {},
   "source": [
    "# Building and training the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8694f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 138)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2208)              306912    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 138)         0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 8, 138)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 256)         317952    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 256)        1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       294912    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        73728     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 3)         9411      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,004,707\n",
      "Trainable params: 1,003,811\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f6ed1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 32, 32, 10)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 13)   0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 64)   20800       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 16, 16, 64)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 16, 16, 64)   0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 128)    204800      ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 8, 8, 128)   256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 8, 8, 128)    0           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 4, 4, 256)    819200      ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 4, 4, 256)   512         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 4, 4, 256)    0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 2, 2, 512)    3276800     ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 2, 2, 512)   1024        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 2, 2, 512)    0           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2049        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,325,569\n",
      "Trainable params: 4,325,569\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64aa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10gan = imageWGANGP(generator,discriminator,latent_dim = latent_dim, num_classes = num_classes,\n",
    "                        img_height = img_height, img_width = img_width, img_channels = img_channels)\n",
    "cifar10gan.compile(\n",
    "    discriminator_optimizer=Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),\n",
    "    generator_optimizer=Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),\n",
    "    discriminator_loss = wasserstein_discriminator_loss,\n",
    "    generator_loss = wasserstein_generator_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3005ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbk = GANMonitor(num_img = num_classes,latent_dim = latent_dim,num_classes = num_classes,\n",
    "                img_height = img_height, img_width = img_width, img_channels = img_channels, name = \"cifarep2\")\n",
    "checkpoint_path = \"checkpoints_cifar/cifarep2_{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c24a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# comment out if testing on already trained weights, takes lots of time\n",
    "cifar10gan.fit(dataset,epochs=epochs,batch_size=batch_size,callbacks=[cbk,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "378b84cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1273b1c2bf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10gan.load_weights(\"checkpoints_cifar/cifarep2_0050.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b9ce0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "# create a demo cifar-10 image\n",
    "random_latent_vectors = tf.random.normal(shape=(100, latent_dim))\n",
    "arr = np.zeros((100,num_classes))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        arr[i*10+j][i] = 1\n",
    "random_latent_vectors = tf.concat([random_latent_vectors,arr], axis = 1)\n",
    "generated_images = cifar10gan.generator(random_latent_vectors)\n",
    "generated_images = (generated_images * 127.5) + 127.5\n",
    "\n",
    "img = []\n",
    "for i in range(10):\n",
    "    img.append([])\n",
    "    for j in range(10):\n",
    "        numpy_img = generated_images[i*10+j].numpy()\n",
    "        img[i].append(numpy_img)\n",
    "img = np.array(img)\n",
    "img = np.hstack(np.hstack(img))\n",
    "print(img.shape)\n",
    "img = img.reshape((img_height*10, img_width*10, img_channels))\n",
    "img = keras.preprocessing.image.array_to_img(img)\n",
    "img.save(f\"cifar10_demo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2e89c",
   "metadata": {},
   "source": [
    "## Generating CIFAR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13d41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "label_list = []\n",
    "for label in range(10):\n",
    "    for _ in range(100):\n",
    "        random_latent_vectors = tf.random.normal(shape=(50, latent_dim))\n",
    "        labels = np.full((50), label)\n",
    "        labels = keras.utils.to_categorical(labels,num_classes)\n",
    "        random_latent_vectors = tf.concat([random_latent_vectors,labels], axis = 1)\n",
    "        generated_imgs = cifar10gan.generator(random_latent_vectors)\n",
    "        img_list.append(generated_imgs)\n",
    "        label_list.append(labels)\n",
    "generated_images = tf.reshape(tf.stack(img_list), [50000, 32, 32, 3])\n",
    "generated_labels = tf.reshape(tf.stack(label_list), [50000, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f0ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_labels = np.argmax(generated_labels, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef808c8",
   "metadata": {},
   "source": [
    "## Classification test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e2cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier():\n",
    "    classifier = Sequential([\n",
    "      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "      layers.MaxPooling2D((2, 2)),\n",
    "      layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      layers.MaxPooling2D((2, 2)),\n",
    "      layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(10)\n",
    "    ])\n",
    "    classifier.compile(\n",
    "        optimizer=Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc6fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = make_classifier()\n",
    "classifier2 = make_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbcbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1fb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gotta normalize x_test\n",
    "x_test_norm = (x_test.astype(\"float32\") - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "467e2cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 1.4243 - accuracy: 0.4869 - val_loss: 1.1719 - val_accuracy: 0.5797\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0721 - accuracy: 0.6248 - val_loss: 1.0122 - val_accuracy: 0.6413\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9224 - accuracy: 0.6794 - val_loss: 0.9686 - val_accuracy: 0.6597\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8288 - accuracy: 0.7099 - val_loss: 0.9191 - val_accuracy: 0.6831\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7542 - accuracy: 0.7369 - val_loss: 0.8508 - val_accuracy: 0.7072\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6992 - accuracy: 0.7556 - val_loss: 0.8367 - val_accuracy: 0.7092\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6433 - accuracy: 0.7746 - val_loss: 0.8852 - val_accuracy: 0.7051\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5984 - accuracy: 0.7898 - val_loss: 0.8728 - val_accuracy: 0.6982\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5598 - accuracy: 0.8027 - val_loss: 0.8571 - val_accuracy: 0.7210\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5166 - accuracy: 0.8188 - val_loss: 0.8800 - val_accuracy: 0.7102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12937e6e1d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training on real data\n",
    "classifier1.fit(x_train, y_train, epochs = 10, batch_size = batch_size, validation_data=(x_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5413c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1619 - accuracy: 0.5903 - val_loss: 2.0380 - val_accuracy: 0.4124\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7463 - accuracy: 0.7386 - val_loss: 2.2636 - val_accuracy: 0.4080\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6112 - accuracy: 0.7852 - val_loss: 2.5898 - val_accuracy: 0.4006\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5337 - accuracy: 0.8137 - val_loss: 2.7658 - val_accuracy: 0.4112\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4765 - accuracy: 0.8307 - val_loss: 3.0572 - val_accuracy: 0.4018\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4319 - accuracy: 0.8469 - val_loss: 2.9221 - val_accuracy: 0.4038\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3948 - accuracy: 0.8590 - val_loss: 3.2799 - val_accuracy: 0.3896\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3661 - accuracy: 0.8700 - val_loss: 3.6228 - val_accuracy: 0.3905\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3429 - accuracy: 0.8777 - val_loss: 3.9409 - val_accuracy: 0.3928\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3161 - accuracy: 0.8880 - val_loss: 3.7435 - val_accuracy: 0.3952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12938937910>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training on generated data\n",
    "classifier2.fit(generated_images, generated_labels, epochs = 10, batch_size = batch_size, validation_data=(x_test_norm, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
